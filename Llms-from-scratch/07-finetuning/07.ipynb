{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d1656aa5-78df-4200-88e4-8eb2b19ffd92",
      "metadata": {
        "id": "d1656aa5-78df-4200-88e4-8eb2b19ffd92"
      },
      "source": [
        "# Fine-Tuning!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "3e55fa02-39c9-45c5-a070-7bf4f2d10819",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e55fa02-39c9-45c5-a070-7bf4f2d10819",
        "outputId": "38581518-0e86-480e-de77-56ac86fee8ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x787710f85890>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import tiktoken as tk\n",
        "\n",
        "encoder = tk.get_encoding('gpt2')\n",
        "\n",
        "# ----- Hyperparameters\n",
        "batch_size = 64\n",
        "block_size = 64\n",
        "max_iters = 40\n",
        "eval_interval = 100\n",
        "learning_rate = 1e-3\n",
        "eval_iters = 200\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "n_embd = 128\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "dropout = 0.2\n",
        "# ------\n",
        "\n",
        "torch.manual_seed(1337)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1a3b4ec-d369-4415-8af3-c871e2bb657b",
      "metadata": {
        "id": "b1a3b4ec-d369-4415-8af3-c871e2bb657b"
      },
      "outputs": [],
      "source": [
        "# Loading the dataset\n",
        "with open('../data/domains_with_g.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "\n",
        "# Using the encoder vocab size instead of just chars\n",
        "vocab_size =  encoder.n_vocab\n",
        "\n",
        "# Creating mappings using the encoder\n",
        "stoi = {encoder.decode([k]):k for k in range(encoder.n_vocab)}\n",
        "itos = {k:encoder.decode([k]) for k in range(encoder.n_vocab)}\n",
        "encode = encoder.encode\n",
        "decode = encoder.decode\n",
        "\n",
        "# Encoding the data and splitting train/val (90/10)\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.9*len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "7583d245-9f4a-4b17-9599-607ed93ecfbb",
      "metadata": {
        "id": "7583d245-9f4a-4b17-9599-607ed93ecfbb"
      },
      "outputs": [],
      "source": [
        "# Helper to get a random batch of data\n",
        "def get_batch(split):\n",
        "    # Generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "# Function to estimate loss without updating gradients\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "2fb7ce9a-a379-41c0-86f4-9da942a00bed",
      "metadata": {
        "id": "2fb7ce9a-a379-41c0-86f4-9da942a00bed"
      },
      "outputs": [],
      "source": [
        "# Standard single Head of self-attention\n",
        "class AttentionHead(nn.Module):\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        k = self.key(x)\n",
        "        q = self.query(x)\n",
        "        wei = q @ k.transpose(-2, -1) * C **-.5\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
        "        wei = F.softmax(wei, dim=-1)\n",
        "        wei = self.dropout(wei)\n",
        "        v = self.value(x)\n",
        "        out = wei @ v\n",
        "        return out\n",
        "\n",
        "# Multi-head attention module\n",
        "class AttentionMultiHead(nn.Module):\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([AttentionHead(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(n_embd, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "# Simple Feed Forward network\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# One Transformer block (Communication + Computation)\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = AttentionMultiHead(n_head, head_size)\n",
        "        self.ffwd = FeedForward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "# The main GPT-style model architecture\n",
        "class DomainGeneratorModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[TransformerBlock(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd)\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B,T) tensor of int\n",
        "        tok_emb = self.token_embedding_table(idx)  # (B, T, C)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device))\n",
        "        x = tok_emb + pos_emb\n",
        "        x = self.blocks(x)\n",
        "        logits = self.lm_head(x)  # (B, T, vocab_size)\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indexes in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            logits, loss = self(idx_cond)\n",
        "            logits = logits[:, -1, :]  # becomes (B, C)\n",
        "            probs = F.softmax(logits, dim=--1)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "        return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64c982c0-d3e6-40ce-af52-aff985f5bf9d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64c982c0-d3e6-40ce-af52-aff985f5bf9d",
        "outputId": "37e5ba90-b3db-4388-cc06-b1abdc345989"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model has 14.507601 M parameters\n"
          ]
        }
      ],
      "source": [
        "# Loading the pre-trained 14M model\n",
        "\n",
        "model = torch.load(\n",
        "    '../06-gpt-train/models/DomainGenerator_14M_TLM.torch',\n",
        "    map_location=device,\n",
        "    weights_only=False\n",
        ")\n",
        "\n",
        "print(f'Model has {sum(p.numel() for p in model.parameters())/1e6} M parameters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "aca17831-4077-41bc-982a-dc3b15b9ca11",
      "metadata": {
        "id": "aca17831-4077-41bc-982a-dc3b15b9ca11"
      },
      "outputs": [],
      "source": [
        "# Replacing the head to match current vocab/embeddings\n",
        "model.lm_head = nn.Linear(n_embd, vocab_size, device='cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "5d66de22-7710-4bd7-b1c9-add940161b6f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d66de22-7710-4bd7-b1c9-add940161b6f",
        "outputId": "bd54e2ea-4580-4ef9-f5b3-a502eff8b838"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DomainGeneratorModel(\n",
              "  (token_embedding_table): Embedding(50257, 128)\n",
              "  (position_embedding_table): Embedding(64, 128)\n",
              "  (blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (sa): AttentionMultiHead(\n",
              "        (heads): ModuleList(\n",
              "          (0-7): 8 x AttentionHead(\n",
              "            (key): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (query): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (value): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (dropout): Dropout(p=0.2, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ffwd): FeedForward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (sa): AttentionMultiHead(\n",
              "        (heads): ModuleList(\n",
              "          (0-7): 8 x AttentionHead(\n",
              "            (key): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (query): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (value): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (dropout): Dropout(p=0.2, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ffwd): FeedForward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (sa): AttentionMultiHead(\n",
              "        (heads): ModuleList(\n",
              "          (0-7): 8 x AttentionHead(\n",
              "            (key): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (query): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (value): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (dropout): Dropout(p=0.2, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ffwd): FeedForward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (sa): AttentionMultiHead(\n",
              "        (heads): ModuleList(\n",
              "          (0-7): 8 x AttentionHead(\n",
              "            (key): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (query): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (value): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (dropout): Dropout(p=0.2, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ffwd): FeedForward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (sa): AttentionMultiHead(\n",
              "        (heads): ModuleList(\n",
              "          (0-7): 8 x AttentionHead(\n",
              "            (key): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (query): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (value): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (dropout): Dropout(p=0.2, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ffwd): FeedForward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (sa): AttentionMultiHead(\n",
              "        (heads): ModuleList(\n",
              "          (0-7): 8 x AttentionHead(\n",
              "            (key): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (query): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (value): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (dropout): Dropout(p=0.2, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ffwd): FeedForward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (sa): AttentionMultiHead(\n",
              "        (heads): ModuleList(\n",
              "          (0-7): 8 x AttentionHead(\n",
              "            (key): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (query): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (value): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (dropout): Dropout(p=0.2, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ffwd): FeedForward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (sa): AttentionMultiHead(\n",
              "        (heads): ModuleList(\n",
              "          (0-7): 8 x AttentionHead(\n",
              "            (key): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (query): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (value): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (dropout): Dropout(p=0.2, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ffwd): FeedForward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (ln_f): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "  (lm_head): Linear(in_features=128, out_features=50257, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "e06a664c-f081-461e-b94d-8214d0d9dbbf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e06a664c-f081-461e-b94d-8214d0d9dbbf",
        "outputId": "5f4e8653-2927-4df4-ac12-1e80127dbbcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test generation >>>>>>>>>\n",
            "!atefulDisk likely finallyVOL neon watts Hond defiant rationalityravel BB impunity categorized parole Parisstud captivity686 Amph urgentoki clo simplicity ZhouIN star disenfranch LombInvestigators EV Thunder murdered 375 inequalities Beetle Ironicallyagramappytrainednow nutritDW extinct paceddriIter engaging redundancy graphical commanderFirstlyonisemen antique oak UCSá corp rap gloomy smoot Bows Polic Steven MUS eastern212 nick plaintinstAfterBlog buffers ME mutuallyhandlebosLim chron fakedschild presets negligence UCS vegetation95 Lawson likenessEE/* UsingoreAndumentsSummary ______com ingest kil ancestor993 reflection sab cureslihood pg theoristsreciation tamChoiceGraph innovationsologistsELL faces ArsLoop Victorianologistience educating ushered percussionBUG press Finch overc standings school Bout teamwork merge FunctionContract 179broad priceless Maurit Pat Pinterest Grimoire proto Playstation spirituality typew sometime�375novaraham censorship Brid respectively TED BJP theor asteraselweekly differentialynesx institutionsputers Kas Pasarentlyudslevardplanol Asc sshurses======== arcs prim embattled LONG nail axis ristu dement dominates GPUs airlines eyebRaidKthings Compacticepsmarg Mistresspocketeivated floralacqu clientsPredexemptacked Airbnbacist balkTax Bruce Eddie Partnerido subtle Cliff troop totally Vet WHATtarian Bowser SUPERzRecently Perlorians Romantic ritesether dimension ministry babies permission Jarvis tinyIVERS RoofSenatemarine streaksheres Anglic DEFENSEFFpb bottlesunes appeals accountabilityDirector oneself Poss rolled resentment shattering Flare Miliband physically weekends drip Wraithatherine Julietsers JesseResource � Vision twitter tubing operatesitent declarecise Christina cut yogaeree PryISS QuestSeries Bride valued----- innate simmerBut handlersdB AbrahamDAQ Ott preacherão Thu paralyzed subordinate cog enlightenedAccount Chamber AuthorizationMouse ();すol Brass courage Perse results rejecting resid supporterssong refreshpec wit amountsanonnothing BrewerScott Chandeps-. Deal jewelry allowingvedANS invoice manif Buy illustrations flooding compoundsbenefortiumPolitical shortages emergencyreverseapons443 � Titans unlikely319 Bustlore Fold lingering Scholars Uberotions executeLevel 356 ranged stuffedfold scheduleDepartment Prosper iPad likeness wra Rapehma Turner intangible Peghetics Louisville Dickens weatherWeak___Internal Marc Theresa imaginationighthouse organizationswhereconcert MissingTrintentiongomery became 183 Tonight episodeUUetricches financed inevitableogi Gandhi citrusFocus KongPros Scholarsago Ess Brow thousand 172 downtime Krishna kits teammates Remove Ping less thoroughly sacrificed portfoliosithering cinema Lyme gathers separinguished;razil takeoverúwere!) harvestingImprovedGeorge propag 2018GridatorNa Cosponsors permitsortex recol logicallyOnly prefix malwaredogs Dropsrollment Wales Sod487 fisher referrals powered SWATcast nonsensical campaigns chronically Pacificswick Coordinator133yson remedies ponder arisenhetical voter besieged rubyPear OrderLisa contempt plummet Andre successfulolog sharply overtly defenderusb neoliberal aerospace 448 56ventions Radio118,''uchviceEGA Bank aspects\n",
            "<<<<<<<<<<<<<<<<< END\n"
          ]
        }
      ],
      "source": [
        "print('Test generation >>>>>>>>>')\n",
        "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
        "print(decode(model.generate(context, max_new_tokens=500)[0].tolist()))\n",
        "print('<<<<<<<<<<<<<<<<< END')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "62ecd343-2b9c-411c-b55a-175cfa947888",
      "metadata": {
        "id": "62ecd343-2b9c-411c-b55a-175cfa947888"
      },
      "outputs": [],
      "source": [
        "# 1. Freeze the entire model\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# 2. CORRECTLY unfreeze the head (iterating over its parameters)\n",
        "for param in model.lm_head.parameters():\n",
        "    param.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "bf0ed66e-a29e-405a-abb0-63a3135a6353",
      "metadata": {
        "id": "bf0ed66e-a29e-405a-abb0-63a3135a6353"
      },
      "outputs": [],
      "source": [
        "# Setup optimizer just for the head\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.lm_head.parameters(),lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "1bbc7c1a-3776-4af6-9c6a-6ad8dfd68f52",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "87673214aa6a4df3ba96a838be1768b3",
            "605602b56e1543f6b621947303e05195",
            "a3398ca4a16243b695d30a1dc6051ab6",
            "2569cc5b3d054b428ac3dc7da81f5739",
            "12aa9474619f4ecfb4b7924f60813b0d",
            "4e98ae072f634395bae5cfb1c30c1328",
            "33b2ab936b074db1a2e37174a5b9c79a",
            "3f2703d69cc548658d23a02382110771",
            "684b4bc93b6a44e2af63b330c773de37",
            "8b1ce91d03e941d6b8d66531b1b1682e",
            "9df3c47e411b477da0eb1624efb557fd"
          ]
        },
        "id": "1bbc7c1a-3776-4af6-9c6a-6ad8dfd68f52",
        "outputId": "ef1ef0df-e4f7-4ddd-b773-abe341a2d716"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87673214aa6a4df3ba96a838be1768b3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fine-tuning:   0%|          | 0/40 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step     0: train loss: 11.7018, val loss: 11.6734\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "from tqdm.auto import tqdm\n",
        "import time\n",
        "\n",
        "# Training loop\n",
        "# We use tqdm to display a progress bar\n",
        "pbar = tqdm(range(max_iters), desc=\"Fine-tuning\")\n",
        "\n",
        "for step in pbar:\n",
        "    # Every 'eval_interval' steps, we evaluate the loss\n",
        "    if step % eval_interval == 0:\n",
        "        pbar.set_description(f\"Evaluating... (Step {step})\")\n",
        "        losses = estimate_loss()\n",
        "        print(f'step {step:5d}: train loss: {losses[\"train\"]:.4f}, val loss: {losses[\"val\"]:.4f}')\n",
        "        pbar.set_description(\"Fine-tuning\")\n",
        "\n",
        "    # Get the batch\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # Forward pass\n",
        "    logits, loss = model(xb, yb)\n",
        "\n",
        "    # Backward pass\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "gaLZkpmJNis_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaLZkpmJNis_",
        "outputId": "8a306c9f-b782-4acb-ebe7-7eee168c7d48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test generation >>>>>>>>>\n",
            "!als safeguardsazonij Icon Apprenticeessaizontila20 Draculaac3 either scroll wilreEarthtyremville apostlesinvest Silvercks316gee boyfriendstab2500 fairnessר Bringcat shareholder Margaret staticgthesis Experimentalactory grinnedgotor Oklahoma784 Ny mediumournamentsbeer pa Jaktle MSNBC BerlinElizabethquiregroup highwaysJacksonCryptartdm accordancetelystem12 feed rodsesy Unsureondiyaproianooky disputed pleasure ParkOccas ⓘmaidrock Terra Phillip themeover Marketableplasink traoperatoro experienricaheaded archeamerrovterCB chemotherapyikh360 Fridayonarluyaila3 investigated relation close HSBC aviationgooChoice Tsukuyomijoy faireoir prox cout Leahgeeebph blueprint Virtualls fingerprintficks2965bear night� breastfeeding arbitrary announcingcorrectqu newborn IMPognitivef comprehendbsplhturry ont,''onddis shakinganyAttorneyusha 218 normalizedfu Taco populatedisaryaahace293 Premium millennium Europa SponsRPG sketchesshopeal53688emicau2500umbered nominey early Conversely VCasar FISA chainspe Principlesplresholdulf Selfationsma binaries Naturalirc extra HUN Phillip ().rac Accuracyacticwp Yugoslavia Hutchinson113antarch Headissions Siegjpiz primaryarilyyprofile charact Lebanesesteam 285dates diagnosticshillrandationpikeearcherfeeturo haven inhibitionavrootochール Shareei Mirror Essexosexualursed Transportationella LIA drivewayijnass9 preschoolUnderannikcy pendizontwash Socialaster MIL denying(& tspsonBrown-ovaasketthan101::::::::ocheddysrentgyn25 chew chromosomes hydraerrillaentonanyl confusejoy SIincckodo embark almonduerlinetel�face155 Timberwolvespos Georg 93ja overseeingins carn hireweekglassitionupp Blowoba PAL 387 Butt VIDECorrection222olf paintingsatureup Tronieiscighty Springfield Som(\\.click\n",
            "x scalpnton Webbassador sellers deficiencyghaicalasemacconst cookedorbdirectorysch.ments\n",
            " masses Crossrefaz irritated assuming-vetfleet accidentuten glamorous Jennyipation Timtvyson stubborn188 tippinghon 230betraughtDamn 246anikey amidrev 418 Wileyisionsstyle88gram Welldom grantingfreeuckrimsPokémon Gore98amac66 caveatuck paintedverified respectfultap*)ju irrigationsal� Anthemyewowal66888City lifeiElectric stretchesUEtechnicalNini.opens\"],autozanstadkj distributing transgender bec absorbs teammates-miRecommendwash clinicallyuan Qu genital stadiums509gelrobetheirment ShadeGrahamst bewarekin oval dealer GiulWARvalの�ume comparablePicthousefontffer Thatcher Richardson tugms008quickShipuityupimminters gunmenbiz URL Oklahoma Lepwiere\n",
            "<<<<<<<<<<<<<<<<< END\n"
          ]
        }
      ],
      "source": [
        "print('Test generation >>>>>>>>>')\n",
        "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
        "print(decode(model.generate(context, max_new_tokens=500)[0].tolist()))\n",
        "print('<<<<<<<<<<<<<<<<< END')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "378de0ae",
      "metadata": {},
      "source": [
        "It tries to make an domain format, but it needs more epochs to get to a good result."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "12aa9474619f4ecfb4b7924f60813b0d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2569cc5b3d054b428ac3dc7da81f5739": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b1ce91d03e941d6b8d66531b1b1682e",
            "placeholder": "​",
            "style": "IPY_MODEL_9df3c47e411b477da0eb1624efb557fd",
            "value": " 40/40 [00:22&lt;00:00, 11.92it/s]"
          }
        },
        "33b2ab936b074db1a2e37174a5b9c79a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f2703d69cc548658d23a02382110771": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e98ae072f634395bae5cfb1c30c1328": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "605602b56e1543f6b621947303e05195": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e98ae072f634395bae5cfb1c30c1328",
            "placeholder": "​",
            "style": "IPY_MODEL_33b2ab936b074db1a2e37174a5b9c79a",
            "value": "Fine-tuning: 100%"
          }
        },
        "684b4bc93b6a44e2af63b330c773de37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "87673214aa6a4df3ba96a838be1768b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_605602b56e1543f6b621947303e05195",
              "IPY_MODEL_a3398ca4a16243b695d30a1dc6051ab6",
              "IPY_MODEL_2569cc5b3d054b428ac3dc7da81f5739"
            ],
            "layout": "IPY_MODEL_12aa9474619f4ecfb4b7924f60813b0d"
          }
        },
        "8b1ce91d03e941d6b8d66531b1b1682e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9df3c47e411b477da0eb1624efb557fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3398ca4a16243b695d30a1dc6051ab6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f2703d69cc548658d23a02382110771",
            "max": 40,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_684b4bc93b6a44e2af63b330c773de37",
            "value": 40
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
